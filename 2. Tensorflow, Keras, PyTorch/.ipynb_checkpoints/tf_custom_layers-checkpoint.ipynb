{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3101b3c3-2fea-4f6b-91e3-bf519dbc3867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1438571-a001-4456-8c82-1f4445d7d789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d26c6c7f-28b4-49cd-9b41-cffdff1904ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = tf.keras.layers.Dense(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d133d46-06a1-41b7-9a7d-abcef2d57ad2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 100), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(tf.zeros([10, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2ebd902-fe19-41f0-b5a4-7b36358c1219",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Variable path=dense_3/kernel, shape=(5, 100), dtype=float32, value=[[-0.16954021  0.06232132 -0.22551064 -0.17500578  0.00460139  0.0265138\n",
       "   -0.05798075  0.16447107 -0.07457492 -0.13405299  0.05767687 -0.07459994\n",
       "    0.20920862 -0.03842036 -0.06676301  0.2001489  -0.03017628  0.17061384\n",
       "    0.04707845 -0.02750075 -0.1558738   0.22986634 -0.18764995 -0.00907721\n",
       "    0.1667882  -0.03091262 -0.03706883  0.19574608 -0.00254001  0.1935967\n",
       "   -0.04297763 -0.06355432 -0.0053848  -0.1246903   0.14132564  0.11558722\n",
       "   -0.14563526  0.15194921 -0.10138737 -0.11131519  0.18835746 -0.18915182\n",
       "    0.12203039 -0.05324782 -0.2264911   0.01441689  0.22312514 -0.22245587\n",
       "    0.13771929 -0.13760033  0.1131257  -0.00467223 -0.15448189  0.1455443\n",
       "   -0.10891169 -0.18187183 -0.01632106  0.21590595 -0.10960096  0.23233287\n",
       "    0.07845826 -0.04412827 -0.15010875  0.16021843  0.07712997 -0.13739586\n",
       "   -0.06421423  0.18220513 -0.15687792  0.21525703 -0.14193124  0.05539976\n",
       "    0.05850907 -0.16456097 -0.05080898  0.00794983  0.1860456  -0.02679916\n",
       "   -0.23401012  0.18974693  0.0928746   0.00777885  0.03590007  0.06007518\n",
       "    0.20113163 -0.04904881 -0.12907021  0.15025128  0.01154511  0.12214892\n",
       "    0.14361726  0.10061772 -0.16736919 -0.18487844 -0.11030978  0.08625601\n",
       "   -0.08784476 -0.2034452  -0.15964116  0.06895138]\n",
       "  [-0.01023343  0.03212343 -0.16747011  0.01072453  0.18440105  0.15768312\n",
       "   -0.05713314  0.15000422 -0.1576687  -0.0367547   0.13104405  0.22872128\n",
       "    0.07661127  0.02770816 -0.05458151  0.1062748  -0.15650159  0.17666079\n",
       "    0.1862454  -0.11433183 -0.17948747 -0.04817727  0.0313061   0.14054169\n",
       "    0.18098201 -0.06298403 -0.11184147  0.08522348  0.03614111  0.08518924\n",
       "   -0.23850054 -0.01969869  0.10593916 -0.13301201 -0.10077909  0.01151974\n",
       "    0.12197323  0.19120209 -0.10522304 -0.03682627 -0.12399333  0.23624788\n",
       "   -0.15565148 -0.20850417  0.14414729 -0.03905122  0.17768563  0.00874078\n",
       "    0.19433914 -0.10818143 -0.00513233  0.03128256 -0.00657265  0.10599752\n",
       "   -0.15044233  0.23382802 -0.08696119 -0.17133127 -0.17348954 -0.1905644\n",
       "   -0.17225295 -0.09044249  0.01382376 -0.18896939 -0.09505038 -0.21226497\n",
       "   -0.12862116  0.01628409 -0.13048135 -0.08837798  0.00707088  0.1469795\n",
       "    0.06652923 -0.01012     0.04331891  0.11560066  0.21526988  0.08650766\n",
       "    0.23881315  0.17201991  0.03478695  0.1556906  -0.17083037  0.20306335\n",
       "    0.02694394  0.196       0.2111874   0.10044469  0.02094091 -0.07642172\n",
       "    0.20053093 -0.18551858 -0.19908968  0.16893958 -0.19860342 -0.18469127\n",
       "    0.10286428  0.01215334 -0.1656872  -0.09369993]\n",
       "  [-0.03224427  0.20191933 -0.01042749 -0.18661329  0.22089149  0.09946413\n",
       "    0.07555623  0.1170163   0.09561847  0.08314775 -0.09998597  0.00191662\n",
       "    0.04266538  0.10308422  0.07366081  0.09715889 -0.17095113  0.13615797\n",
       "   -0.11203633  0.17095329 -0.10274705 -0.09366676  0.02672444 -0.04891123\n",
       "    0.16211604 -0.15737079  0.2334358   0.0782171  -0.1657849  -0.15378086\n",
       "   -0.01453218 -0.03536378  0.07151754  0.12049107  0.00152086 -0.00698984\n",
       "   -0.22933526 -0.14704852  0.06552057  0.19754134 -0.19197018  0.0362259\n",
       "    0.05820079 -0.16776648  0.2094966  -0.08647335  0.18172325  0.12640561\n",
       "   -0.04481623  0.11902075  0.06155877  0.12265565 -0.17063276 -0.0341744\n",
       "   -0.04146065  0.20827995  0.15584354 -0.17621917  0.14944471  0.00502843\n",
       "   -0.02033411 -0.23705474 -0.00323868 -0.0277897   0.02622695 -0.14805397\n",
       "   -0.1699855   0.21198438  0.14917733 -0.11562324  0.06014977 -0.09447725\n",
       "    0.03922369 -0.23622823 -0.01732431 -0.03480935 -0.11802919  0.11912818\n",
       "   -0.12111843 -0.0724027   0.1960255   0.08628805 -0.10583988  0.19260211\n",
       "    0.11738883 -0.05404784 -0.19585106 -0.13571495  0.12508442 -0.08829837\n",
       "    0.06155123  0.03033955  0.1518961   0.09193026  0.0710649   0.14155178\n",
       "   -0.06176947  0.1908551   0.21994956  0.09192003]\n",
       "  [-0.11441635  0.19653653 -0.0157977  -0.06255797 -0.16099411  0.19159783\n",
       "    0.09545843 -0.13859636  0.07625867  0.22339843  0.10291262  0.17548715\n",
       "   -0.19458348 -0.19133699 -0.20461561 -0.0971553   0.13612576 -0.16572715\n",
       "   -0.11018047 -0.12377146 -0.21358931 -0.09745662 -0.13035956 -0.05781399\n",
       "    0.08445846 -0.22764651 -0.06498192  0.23327474 -0.11463013 -0.19180605\n",
       "   -0.1643619  -0.10133761  0.01264296  0.15774684  0.19224478  0.01341368\n",
       "    0.22507037  0.23873283  0.2286473  -0.01776071  0.14042293 -0.23866381\n",
       "    0.05817406 -0.02150624  0.08815287 -0.03350553  0.1889366   0.12949668\n",
       "    0.21614738 -0.1949561   0.16331403 -0.11273266 -0.11077148 -0.02423197\n",
       "    0.10683177 -0.07741158 -0.00361061  0.13355042 -0.20008843  0.22149812\n",
       "   -0.04916337 -0.22784273  0.19306825 -0.17258084  0.11666791 -0.04654716\n",
       "    0.06096335  0.01156659 -0.08583491 -0.01928054  0.02675341 -0.10010429\n",
       "   -0.04565328  0.05983992 -0.11141795 -0.06023316  0.22969858 -0.13947365\n",
       "    0.05409543  0.18306123  0.1059721   0.1285445   0.20506625 -0.01455018\n",
       "   -0.15204959 -0.01916416 -0.10889111 -0.18925309 -0.17311156  0.17452322\n",
       "    0.04043032  0.17517631 -0.17838494  0.19054486 -0.01531827  0.16307686\n",
       "    0.07220881 -0.139656   -0.1844066  -0.12610474]\n",
       "  [-0.13382342  0.19632708  0.16826065 -0.01353827  0.14544336  0.146259\n",
       "   -0.00785984  0.094106   -0.20961764 -0.03851812 -0.19047713 -0.06005968\n",
       "   -0.09814794  0.09155054  0.16987129 -0.20439014  0.14416085  0.2209829\n",
       "   -0.05795214 -0.00534634 -0.12944272  0.15290488 -0.22161323  0.15987279\n",
       "   -0.19670829 -0.20211715  0.14905708 -0.12331187  0.07874788 -0.18506674\n",
       "    0.0673248  -0.06944299 -0.09368113  0.11824997  0.18501703 -0.1865233\n",
       "    0.17192946  0.19920869 -0.14554094 -0.13079846  0.18024503 -0.2093561\n",
       "   -0.21266842  0.0333835   0.18512686 -0.22292846  0.16181253 -0.13819546\n",
       "    0.10928603  0.15025972 -0.15976147  0.18372335 -0.18324827 -0.01910597\n",
       "   -0.18075305  0.01861925 -0.22437005 -0.09979977  0.03983442 -0.23541544\n",
       "   -0.20118338  0.01232581  0.22592594  0.00860263 -0.19268607 -0.16745068\n",
       "   -0.22125612 -0.10803337 -0.00642709  0.06295891 -0.19436269  0.2200049\n",
       "   -0.16464457 -0.14133069  0.02384059  0.22002913 -0.1806581   0.15196918\n",
       "    0.18443833  0.04543586 -0.12788281  0.17736773  0.08594428  0.12671162\n",
       "    0.13181426  0.16521318 -0.20235246  0.07467927  0.2142363  -0.06236817\n",
       "    0.05304144 -0.01177531 -0.0856556   0.03661112  0.12902166  0.14247619\n",
       "    0.2347847  -0.02392501 -0.0651904   0.0661393 ]]>,\n",
       " <Variable path=dense_3/bias, shape=(100,), dtype=float32, value=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0.]>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "346d0aa9-26b8-4f2b-9f14-5071001d30b1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Variable path=dense_3/kernel, shape=(5, 100), dtype=float32, value=[[-0.16954021  0.06232132 -0.22551064 -0.17500578  0.00460139  0.0265138\n",
       "   -0.05798075  0.16447107 -0.07457492 -0.13405299  0.05767687 -0.07459994\n",
       "    0.20920862 -0.03842036 -0.06676301  0.2001489  -0.03017628  0.17061384\n",
       "    0.04707845 -0.02750075 -0.1558738   0.22986634 -0.18764995 -0.00907721\n",
       "    0.1667882  -0.03091262 -0.03706883  0.19574608 -0.00254001  0.1935967\n",
       "   -0.04297763 -0.06355432 -0.0053848  -0.1246903   0.14132564  0.11558722\n",
       "   -0.14563526  0.15194921 -0.10138737 -0.11131519  0.18835746 -0.18915182\n",
       "    0.12203039 -0.05324782 -0.2264911   0.01441689  0.22312514 -0.22245587\n",
       "    0.13771929 -0.13760033  0.1131257  -0.00467223 -0.15448189  0.1455443\n",
       "   -0.10891169 -0.18187183 -0.01632106  0.21590595 -0.10960096  0.23233287\n",
       "    0.07845826 -0.04412827 -0.15010875  0.16021843  0.07712997 -0.13739586\n",
       "   -0.06421423  0.18220513 -0.15687792  0.21525703 -0.14193124  0.05539976\n",
       "    0.05850907 -0.16456097 -0.05080898  0.00794983  0.1860456  -0.02679916\n",
       "   -0.23401012  0.18974693  0.0928746   0.00777885  0.03590007  0.06007518\n",
       "    0.20113163 -0.04904881 -0.12907021  0.15025128  0.01154511  0.12214892\n",
       "    0.14361726  0.10061772 -0.16736919 -0.18487844 -0.11030978  0.08625601\n",
       "   -0.08784476 -0.2034452  -0.15964116  0.06895138]\n",
       "  [-0.01023343  0.03212343 -0.16747011  0.01072453  0.18440105  0.15768312\n",
       "   -0.05713314  0.15000422 -0.1576687  -0.0367547   0.13104405  0.22872128\n",
       "    0.07661127  0.02770816 -0.05458151  0.1062748  -0.15650159  0.17666079\n",
       "    0.1862454  -0.11433183 -0.17948747 -0.04817727  0.0313061   0.14054169\n",
       "    0.18098201 -0.06298403 -0.11184147  0.08522348  0.03614111  0.08518924\n",
       "   -0.23850054 -0.01969869  0.10593916 -0.13301201 -0.10077909  0.01151974\n",
       "    0.12197323  0.19120209 -0.10522304 -0.03682627 -0.12399333  0.23624788\n",
       "   -0.15565148 -0.20850417  0.14414729 -0.03905122  0.17768563  0.00874078\n",
       "    0.19433914 -0.10818143 -0.00513233  0.03128256 -0.00657265  0.10599752\n",
       "   -0.15044233  0.23382802 -0.08696119 -0.17133127 -0.17348954 -0.1905644\n",
       "   -0.17225295 -0.09044249  0.01382376 -0.18896939 -0.09505038 -0.21226497\n",
       "   -0.12862116  0.01628409 -0.13048135 -0.08837798  0.00707088  0.1469795\n",
       "    0.06652923 -0.01012     0.04331891  0.11560066  0.21526988  0.08650766\n",
       "    0.23881315  0.17201991  0.03478695  0.1556906  -0.17083037  0.20306335\n",
       "    0.02694394  0.196       0.2111874   0.10044469  0.02094091 -0.07642172\n",
       "    0.20053093 -0.18551858 -0.19908968  0.16893958 -0.19860342 -0.18469127\n",
       "    0.10286428  0.01215334 -0.1656872  -0.09369993]\n",
       "  [-0.03224427  0.20191933 -0.01042749 -0.18661329  0.22089149  0.09946413\n",
       "    0.07555623  0.1170163   0.09561847  0.08314775 -0.09998597  0.00191662\n",
       "    0.04266538  0.10308422  0.07366081  0.09715889 -0.17095113  0.13615797\n",
       "   -0.11203633  0.17095329 -0.10274705 -0.09366676  0.02672444 -0.04891123\n",
       "    0.16211604 -0.15737079  0.2334358   0.0782171  -0.1657849  -0.15378086\n",
       "   -0.01453218 -0.03536378  0.07151754  0.12049107  0.00152086 -0.00698984\n",
       "   -0.22933526 -0.14704852  0.06552057  0.19754134 -0.19197018  0.0362259\n",
       "    0.05820079 -0.16776648  0.2094966  -0.08647335  0.18172325  0.12640561\n",
       "   -0.04481623  0.11902075  0.06155877  0.12265565 -0.17063276 -0.0341744\n",
       "   -0.04146065  0.20827995  0.15584354 -0.17621917  0.14944471  0.00502843\n",
       "   -0.02033411 -0.23705474 -0.00323868 -0.0277897   0.02622695 -0.14805397\n",
       "   -0.1699855   0.21198438  0.14917733 -0.11562324  0.06014977 -0.09447725\n",
       "    0.03922369 -0.23622823 -0.01732431 -0.03480935 -0.11802919  0.11912818\n",
       "   -0.12111843 -0.0724027   0.1960255   0.08628805 -0.10583988  0.19260211\n",
       "    0.11738883 -0.05404784 -0.19585106 -0.13571495  0.12508442 -0.08829837\n",
       "    0.06155123  0.03033955  0.1518961   0.09193026  0.0710649   0.14155178\n",
       "   -0.06176947  0.1908551   0.21994956  0.09192003]\n",
       "  [-0.11441635  0.19653653 -0.0157977  -0.06255797 -0.16099411  0.19159783\n",
       "    0.09545843 -0.13859636  0.07625867  0.22339843  0.10291262  0.17548715\n",
       "   -0.19458348 -0.19133699 -0.20461561 -0.0971553   0.13612576 -0.16572715\n",
       "   -0.11018047 -0.12377146 -0.21358931 -0.09745662 -0.13035956 -0.05781399\n",
       "    0.08445846 -0.22764651 -0.06498192  0.23327474 -0.11463013 -0.19180605\n",
       "   -0.1643619  -0.10133761  0.01264296  0.15774684  0.19224478  0.01341368\n",
       "    0.22507037  0.23873283  0.2286473  -0.01776071  0.14042293 -0.23866381\n",
       "    0.05817406 -0.02150624  0.08815287 -0.03350553  0.1889366   0.12949668\n",
       "    0.21614738 -0.1949561   0.16331403 -0.11273266 -0.11077148 -0.02423197\n",
       "    0.10683177 -0.07741158 -0.00361061  0.13355042 -0.20008843  0.22149812\n",
       "   -0.04916337 -0.22784273  0.19306825 -0.17258084  0.11666791 -0.04654716\n",
       "    0.06096335  0.01156659 -0.08583491 -0.01928054  0.02675341 -0.10010429\n",
       "   -0.04565328  0.05983992 -0.11141795 -0.06023316  0.22969858 -0.13947365\n",
       "    0.05409543  0.18306123  0.1059721   0.1285445   0.20506625 -0.01455018\n",
       "   -0.15204959 -0.01916416 -0.10889111 -0.18925309 -0.17311156  0.17452322\n",
       "    0.04043032  0.17517631 -0.17838494  0.19054486 -0.01531827  0.16307686\n",
       "    0.07220881 -0.139656   -0.1844066  -0.12610474]\n",
       "  [-0.13382342  0.19632708  0.16826065 -0.01353827  0.14544336  0.146259\n",
       "   -0.00785984  0.094106   -0.20961764 -0.03851812 -0.19047713 -0.06005968\n",
       "   -0.09814794  0.09155054  0.16987129 -0.20439014  0.14416085  0.2209829\n",
       "   -0.05795214 -0.00534634 -0.12944272  0.15290488 -0.22161323  0.15987279\n",
       "   -0.19670829 -0.20211715  0.14905708 -0.12331187  0.07874788 -0.18506674\n",
       "    0.0673248  -0.06944299 -0.09368113  0.11824997  0.18501703 -0.1865233\n",
       "    0.17192946  0.19920869 -0.14554094 -0.13079846  0.18024503 -0.2093561\n",
       "   -0.21266842  0.0333835   0.18512686 -0.22292846  0.16181253 -0.13819546\n",
       "    0.10928603  0.15025972 -0.15976147  0.18372335 -0.18324827 -0.01910597\n",
       "   -0.18075305  0.01861925 -0.22437005 -0.09979977  0.03983442 -0.23541544\n",
       "   -0.20118338  0.01232581  0.22592594  0.00860263 -0.19268607 -0.16745068\n",
       "   -0.22125612 -0.10803337 -0.00642709  0.06295891 -0.19436269  0.2200049\n",
       "   -0.16464457 -0.14133069  0.02384059  0.22002913 -0.1806581   0.15196918\n",
       "    0.18443833  0.04543586 -0.12788281  0.17736773  0.08594428  0.12671162\n",
       "    0.13181426  0.16521318 -0.20235246  0.07467927  0.2142363  -0.06236817\n",
       "    0.05304144 -0.01177531 -0.0856556   0.03661112  0.12902166  0.14247619\n",
       "    0.2347847  -0.02392501 -0.0651904   0.0661393 ]]>,\n",
       " <Variable path=dense_3/bias, shape=(100,), dtype=float32, value=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0.]>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.kernel, layer.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e243079-b5bc-4a8b-a60e-ccb191b832bf",
   "metadata": {},
   "source": [
    "### Implementing custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51fe3c1a-f9b1-4e57-8ada-43cf5d1b8cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDenseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_outputs):\n",
    "        super(MyDenseLayer, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                     shape=[int(input_shape[-1]),\n",
    "                                     self.num_outputs])\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.kernel)\n",
    "\n",
    "layer = MyDenseLayer(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6284520-1476-4c53-b082-7e0fcf73ad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = layer(tf.zeros([10, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "377a91f9-e3ef-4f91-84eb-b026bbca907e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kernel']\n"
     ]
    }
   ],
   "source": [
    "print([var.name for var in layer.trainable_variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a558a3-fae7-422d-9af9-9d0346b340c8",
   "metadata": {},
   "source": [
    "### basic custom layer example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80a6cea2-2265-4a8d-95a7-3d135b7dc9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquarePlusOne(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.square(inputs)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b97dfdc1-deec-4c9a-9e9a-b52fa3aad5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 5. 10.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "layer = SquarePlusOne()\n",
    "print(layer(tf.constant([2.0, 3.0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98039f3e-976b-4e1a-8817-ccce468d03d8",
   "metadata": {},
   "source": [
    "### Custom Layer With Trainable Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d292b754-9bf7-4a82-8ce0-ba615b9fee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer='random_normal',\n",
    "            trainable=True\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,),\n",
    "            initializer='zeros',\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w)+self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ce2ba71-d2a9-4aed-a0c9-ccfa211ceb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.16567433 -0.03797147 -0.07146695 -0.16370553]\n",
      " [ 0.12703589  0.11979033  0.12163882  0.18937778]], shape=(2, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "layer = MyDense(4)\n",
    "print(layer(tf.random.normal((2,3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfada086-783a-436e-a513-7c18f14047c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13 (tf)",
   "language": "python",
   "name": "py313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
