{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9db6108a-b763-46e8-9a5b-f50a1406bcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "538fb1da-a3c0-45a2-be66-85e8384f684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape((-1, 28, 28, 1)).astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f8b23e7-b66b-4d1d-a3a9-2846f69230be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator_cnn():\n",
    "    model = models.Sequential([\n",
    "        \n",
    "        layers.Conv2D(64, kernel_size=3, strides=2, input_shape=(28, 28, 1), padding='same', activation='relu'),\n",
    "        \n",
    "        layers.Conv2D(128, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a33e740-ae53-41a7-9b2c-8e956a6f4270",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_generator_cnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m generator_cnn = \u001b[43mbuild_generator_cnn\u001b[49m()\n\u001b[32m      2\u001b[39m discriminator_cnn = build_discriminator_cnn()\n\u001b[32m      4\u001b[39m discriminator_cnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=\u001b[32m0.01\u001b[39m), \n\u001b[32m      5\u001b[39m                           loss=\u001b[33m'\u001b[39m\u001b[33mbinary_crossentropy\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m      6\u001b[39m                           metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'build_generator_cnn' is not defined"
     ]
    }
   ],
   "source": [
    "generator_cnn = build_generator_cnn()\n",
    "discriminator_cnn = build_discriminator_cnn()\n",
    "\n",
    "discriminator_cnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), \n",
    "                          loss='binary_crossentropy', \n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "discriminator_cnn.trainable = False\n",
    "\n",
    "gan_input = layers.Input(shape=(100,))\n",
    "gan_output = discriminator_cnn(generator_cnn(gan_input))\n",
    "gan_cnn = models.Model(gan_input, gan_output)\n",
    "gan_cnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), \n",
    "                loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cacad37-96f1-4161-8135-c1336270901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100000\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(epochs+1):\n",
    "   \n",
    "    noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "    generated_images = generator_cnn.predict(noise)\n",
    "\n",
    "    idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
    "    real_images = x_train[idx]\n",
    "\n",
    "    real_labels = np.ones((batch_size, 1))\n",
    "    fake_labels = np.zeros((batch_size, 1))\n",
    "\n",
    "    d_loss_real = discriminator_cnn.train_on_batch(real_images, real_labels)\n",
    "    d_loss_fake = discriminator_cnn.train_on_batch(generated_images, fake_labels)\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "    valid_labels = np.ones((batch_size, 1))\n",
    "    g_loss = gan_cnn.train_on_batch(noise, valid_labels)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}: D Loss: {d_loss[0]}, G Loss: {g_loss}\")\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        test_noise = np.random.normal(0, 1, (1, 100))\n",
    "        test_img = generator_cnn.predict(test_noise)[0].reshape(28, 28)\n",
    "        plt.imshow(test_img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10db2130-c533-4db8-ae39-52281dac2bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612fb6e5-1654-4bf9-93ea-9209c1106e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a16fe9e-665e-4e99-9dd8-7c008e0a1e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13 (tf)",
   "language": "python",
   "name": "py313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
